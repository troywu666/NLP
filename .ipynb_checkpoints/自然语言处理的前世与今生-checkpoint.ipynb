{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T15:45:34.128822Z",
     "start_time": "2019-03-26T15:45:13.884436Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T15:46:10.910860Z",
     "start_time": "2019-03-26T15:46:10.807790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《红楼梦》曹雪芹\n",
      "\n",
      "\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\n",
      "\n",
      "在线阅读：http://www.shuyaya.com/read/2034/\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "第一回  甄士隐梦幻识通灵　贾雨村风尘怀闺秀\n",
      "\n",
      "\n",
      "\n",
      "    \t\t\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./hongloumeng.txt',encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        i += 1\n",
    "        if i > 9:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取所有句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T15:46:13.417035Z",
     "start_time": "2019-03-26T15:46:13.385013Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_sentence(text):\n",
    "    text = (text).decode('utf-8')\n",
    "    start = 0\n",
    "    i = 0\n",
    "    sentences = []\n",
    "\n",
    "    #punt_list = ',.!?:;~，。！？：；～'.decode('utf8')\n",
    "    #punt_list = ',.!?:;~，．。！？：；～'.decode('utf-8')\n",
    "    punt_list = '.!?~． 。！？～\\n'.decode('utf-8')\n",
    "    for word in text:\n",
    "        if word in punt_list and token not in punt_list: #检查标点符号下一个字符是否还是标点\n",
    "            sentences.append(text[start:i+1])\n",
    "            start = i+1\n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            token = list(text[start:i+2]).pop() # 取下一个字符\n",
    "    if start < len(text):\n",
    "        sentences.append(text[start:])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T15:46:49.072957Z",
     "start_time": "2019-03-26T15:46:49.051939Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-99e12de273cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./hongloumeng.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcut_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: integer argument expected, got 'str'"
     ]
    }
   ],
   "source": [
    "f = open('./hongloumeng.txt')\n",
    "text = f.read()\n",
    "sentences = cut_sentence(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《红楼梦》曹雪芹\r\n",
      "\n",
      "\r\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.\n",
      "shuyaya.\n",
      "com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\n",
      "\r\n",
      "\n",
      "在线阅读：http://www.\n",
      "shuyaya.\n",
      "com/read/2034/\r\n",
      "\n",
      "--------------------------------------------------\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the first five sentences\n",
    "i = 0\n",
    "while i < 10:\n",
    "    print sentences[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存储清洗后的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_re = re.compile(u'[^\\u4E00-\\u9FA5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('data/cleaned_hongloumeng.txt', 'w')\n",
    "for s in sentences:\n",
    "    cleaned_s = filter_re.sub(r'', s)\n",
    "    if len(cleaned_s) :\n",
    "        f.write(cleaned_s.encode('utf-8')+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_sentences = []\n",
    "for s in sentences:\n",
    "    cleaned_s = filter_re.sub(r'', s)\n",
    "    if len(cleaned_s) :\n",
    "        cleaned_sentences.append(cleaned_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence has to be a tuple\n",
    "generate_ngrams = lambda sentence, n : zip(*[sentence[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.346 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自 又\n",
      "又 云今\n",
      "云今 风尘碌碌\n",
      "风尘碌碌 一事无成\n",
      "一事无成 忽\n",
      "忽 念及\n",
      "念及 当日\n",
      "当日 所有\n",
      "所有 之\n",
      "之 女子\n",
      "女子 一一\n",
      "一一 细考\n",
      "细考 较\n",
      "较 去\n",
      "去 觉\n",
      "觉 其\n",
      "其 行止\n",
      "行止 见识\n",
      "见识 皆\n",
      "皆 出于\n",
      "出于 我\n",
      "我 之上\n",
      "自\n",
      "又\n",
      "云今\n",
      "风尘碌碌\n",
      "一事无成\n",
      "忽\n",
      "念及\n",
      "当日\n",
      "所有\n",
      "之\n",
      "女子\n",
      "一一\n",
      "细考\n",
      "较\n",
      "去\n",
      "觉\n",
      "其\n",
      "行止\n",
      "见识\n",
      "皆\n",
      "出于\n",
      "我\n",
      "之上\n"
     ]
    }
   ],
   "source": [
    "# test generate_ngrams function\n",
    "for bigram in generate_ngrams(list(jieba.cut(cleaned_sentences[10])), 2):\n",
    "    print bigram[0], bigram[1]\n",
    "for unigram in generate_ngrams(list(jieba.cut(cleaned_sentences[10])), 1):\n",
    "    print unigram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cut sentence before the following calculation\n",
    "cut_sentences = [list(jieba.cut(s)) for s in cleaned_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u7ea2\\u697c\\u68a6', u'\\u66f9\\u96ea\\u82b9']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum likelihood parameter estimation \n",
    "def ngrams_parameter_estimate(sentences, n):\n",
    "    sentences_copy = copy.deepcopy(sentences)\n",
    "    ngrams_dict = {}\n",
    "    num_ngrams = 0\n",
    "    for words in sentences_copy:\n",
    "        for i in range(n-1):\n",
    "            words.insert(0, '*')\n",
    "        words.append('#')\n",
    "        ngrams = generate_ngrams(words, n)\n",
    "        for ngram in ngrams:\n",
    "            ngrams_dict[ngram] = ngrams_dict.get(ngram, 0.0) + 1.0\n",
    "            num_ngrams += 1\n",
    "    \n",
    "    # normalize\n",
    "    #for ngram in ngrams_dict:\n",
    "        #ngrams_dict[ngram] /= num_ngrams\n",
    "        \n",
    "    return ngrams_dict, num_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigrams_dict, n_bigrams = ngrams_parameter_estimate(cut_sentences, 1)\n",
    "filtered_unigrams_dict = OrderedDict(sorted([(k, v)  for k, v in unigrams_dict.iteritems() if v >= 10], key = lambda (k, v) : (v, k), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: #, frequency: 34412.0\n",
      "word: 了, frequency: 19613.0\n",
      "word: 今儿, frequency: 286.0\n",
      "word: 一刻, frequency: 10.0\n"
     ]
    }
   ],
   "source": [
    "print 'word: %s, frequency: %s' % (filtered_unigrams_dict.keys()[0][0], filtered_unigrams_dict[filtered_unigrams_dict.keys()[0]])\n",
    "print 'word: %s, frequency: %s' % (filtered_unigrams_dict.keys()[1][0], filtered_unigrams_dict[filtered_unigrams_dict.keys()[1]])\n",
    "print 'word: %s, frequency: %s' % (filtered_unigrams_dict.keys()[200][0], filtered_unigrams_dict[filtered_unigrams_dict.keys()[200]])\n",
    "print 'word: %s, frequency: %s' % (filtered_unigrams_dict.keys()[-1][0], filtered_unigrams_dict[filtered_unigrams_dict.keys()[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'frequency')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4HNWZ7/Hv29plSZZsyZu8SF5ZbGyMY7MFCAkTSAgwWSZAJoQQhiF7yORmnUlyk7lzZ+ZmJUwCBLJAAoGwOgkECDsJmwCDF8B4wbZk2ZYXSba1S+/9o0qmLZfklq1eJP8+z9OPq6tOVb0q6H771Klzjrk7IiIifcXSHYCIiGQmJQgREYmkBCEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEik7HQHMFjl5eVeVVWV7jBERIaVF154Ybu7Vwxmn2GXIKqqqqipqUl3GCIiw4qZbRjsPrrFJCIikZQgREQkkhKEiIhEUoIQEZFIShAiIhJJCUJERCIpQYiISCQlCBERiaQEISIikYZdT+pMc8uzGw9Yd/GSqWmIRERkaKkGISIikZQgREQkkhKEiIhEUoIQEZFIShAiIhJJCUJERCIpQYiISCQlCBERiaQEISIikZQgREQkkhKEiIhEUoIQEZFISUsQZjbFzB41s1VmttLMPh9RxszsajNbY2avmNnCZMUjIiKDk8zRXLuAf3H3F82sGHjBzB5y91VxZc4BZoWvJcDPwn9FRCTNklaDcPd6d38xXN4NvApU9il2PnCTB54BSs1sYrJiEhGRxKWkDcLMqoDjgWf7bKoENsW9r+XAJCIiImmQ9ARhZkXAncAX3L35EI9xhZnVmFlNQ0PD0AYoIiKRkpogzCyHIDn81t3viihSB0yJez85XLcfd7/e3Re5+6KKiorkBCsiIvtJ5lNMBtwIvOruP+in2FLgkvBpphOBJnevT1ZMIiKSuGQ+xXQK8FFguZktC9d9HZgK4O7XAvcB7wHWAC3Ax5MYj4iIDELSEoS7PwXYQco48OlkxSAiIodOPalFRCSSEoSIiERSghARkUhKECIiEkkJQkREIilBiIhIJCUIERGJpAQhIiKRlCBERCSSEoSIiERSghARkUhKECIiEkkJQkREIilBiIhIJCUIERGJpAQhIiKRlCBERCSSEoSIiERSghARkUhKECIiEkkJQkREIilBiIhIJCUIERGJpAQhIiKRlCBERCSSEoSIiERSghARkUhKECIiEkkJQkREIilBiIhIJCUIERGJpAQhIiKRlCBERCSSEoSIiERSghARkUhKECIiEik73QEcKW55dmPk+ouXTE1xJCIiiVENQkREIilBiIhIpKTdYjKzXwDnAtvcfW7E9jOAe4H14aq73P07yYonlfq7nSQiMpwksw3iV8A1wE0DlHnS3c9NYgwiInKIknaLyd2fAHYm6/giIpJc6W6DOMnMXjaz+83s2P4KmdkVZlZjZjUNDQ2pjE9E5IiVzgTxIjDN3ecDPwHu6a+gu1/v7ovcfVFFRUXKAhQROZKlLUG4e7O77wmX7wNyzKw8XfGIiMj+0pYgzGyCmVm4vDiMZUe64hERkf0l8zHXW4EzgHIzqwW+BeQAuPu1wAeBT5pZF9AKXOjunqx4RERkcJKWINz9ooNsv4bgMVgREclA6X6KSUREMpQShIiIRFKCEBGRSEoQIiISSQlCREQiHTRBmNnYVAQiIiKZJZEaxDNm9nsze09vxzY5uI6uHprbOtMdhojIIUukH8Rs4F3AZcDVZnY78Ct3X53UyIa5257fyKtbdjOhJJ/Z44s5fmop40vy0x2WiEjCDlqD8MBDYce3fwI+BjxnZo+b2UlJj3AY2rGnnde27Gb2+CIKc7N4ak0DP3t8LbtVoxCRYeSgNYiwDeIfgY8CW4HPAkuBBcDvgepkBjgcPbt+J2bw/uMnU1KQQ8Pudn788GoeeW0b5y+oTHd4IiIJSaQN4mmgBLjA3d/r7ne5e5e71wDXJje84aejq4eaDTs5dtJoSgpyAKgozmNx9Rief3MnDbvb0xyhiEhiEkkQc9z9u+5e23eDu/9XEmIa1l6ubaSts4cTp+//8NeZR40nOyvGg6u2pCkyEZHBSSRBPGhmpb1vzKzMzB5IYkzDlrvzzLodTCjJp2ps4X7bivKyOW1WOSs3N7Nhx940RSgikrhEEkSFuzf2vnH3XcC45IU0fG3Y0UJ9UxsnTh9L1BPBp86soDgvmz+v2IJGNheRTJdIgug2s6m9b8xsGqBvtwjPvbmT/JwYC6aURm7PzY5xxpwKNuxsoa6xNcXRiYgMTiIJ4hvAU2Z2s5n9BngC+FpywxqeNuzYy8xxxeRm939Zj59aRm5WjGfX70xhZCIig5dIP4g/AwuB24DfASe4u9og+mjv7GZXSycTRw/cGS4/J4sFU0p5pbaR1o7uFEUnIjJ4iQ7WlwfsBJqBY8zstOSFNDxtbW4DYEICvaUXV4+hs9t5adOuZIclInLIEuko91/Ah4GVQE+42gluNUmofhAJYlJpAVPKCnh2/U7cPbJBW0Qk3RIZi+kCgr4Q6uE1gC1NbeRlxygtzEmo/OLqsdz5Yi3Prd/JkukaMFdEMk8it5jWAYl96x3Btja3Mb4kP+HawLzK0eTnxPjtsxuTHJmIyKFJpAbRAiwzs4eBfbUId/9c0qIaZtydLc1tHDc5+vHWKLnZMRZOLeP+FfXs2HMMY4vykhihiMjgJVKDWAp8F/gb8ELcS0JNrZ20dfYk1P4Qb1FV0Fh9z7LNSYpMROTQHbQG4e6/NrMCYKq7v56CmIadLYNooI43oSSfyWUFXP/EWvKzY/tuT128ZOpB9hQRSb5Ephx9H7AM+HP4foGZLU12YMPJlqYwQRykD0SURdPGsLW5ndpd6lktIpklkVtM3wYWA40A7r4MmJ7EmIadLc1tlBbmkJ+TNeh9j5s8mpws44UN6hMhIpklkQTR6e5Nfdb1RJY8Qm1pahv07aVe+TlZzJ00mpdrG+no0mUVkcyRSIJYaWYXA1lmNsvMfkLQYC1AV3cP2/e0H3KCADihqoz2rh5Wbu6bh0VE0ieRBPFZ4FiCR1xvJRhu4wvJDGo42ba7nR4/tPaHXtVjRzF2VC41us0kIhkkkaeYWghGdP1G8sMZfgYzBlN/zIwTppXx4KqtbN+jDusikhkSGYvpUSLmf3D3M5MS0TCzpamN7Jgddke3hVPL+MurW6l5U7UIEckMifSk/lLccj7wAaArOeEMP1ua2xhXnEdW7PAG3CspyGHO+GJe3LiLzu4ecrISHWhXRCQ5ErnF1LfX9F/N7LkkxTPsbN/TzpQxhQcvmIC3VY3h1S0bePjVbZw9d8KQHFNE5FAl0lFuTNyr3MzeDYxOQWwZr6u7h6bWTsYU5g7J8WaNL6YkP5vfPa8B/EQk/RK5xfQCQRuEEdxaWg98IplBDRdbwyeYSocoQWTFgsbqx1Y3sLmxlUmlBUNyXBGRQ5HIlKPV7j49/HeWu/+duz+ViuAyXV04PEZZgnNAJGLRtDEA3F6zaciOKSJyKBJ5iun9A21397uGLpzhpXZXCzB0NQiAslG5nDqznNuf38Rnz5x12I3fIiKHKpFHZT4B3Ah8JHzdAFwGvA84N3mhZb7eGkSis8gl6qLFU9nc1Mbjq7cN6XFFRAYjkQSRAxzj7h9w9w8Q9KrOcfePu/tl/e1kZr8ws21mtqKf7WZmV5vZGjN7xcwWHtqfkD51ja0U5WUP+SOpZx0znnHFedz09IYhPa6IyGAk8s02xd3r495vBRKZsOBXwNkDbD8HmBW+rgB+lsAxM0rtrtYhrz0A5GTFuHjJVB57vYE3t+8d8uOLiCQikQTxsJk9YGaXmtmlwJ+AvxxsJ3d/Atg5QJHzgZs88AxQamYTEwk6U9Q1tlI2hO0P8S5ePJXsmPGbZ1SLEJH0SOQpps8A1wLzw9f17v7ZITh3JRD/qE5tuG5Y6Olx6pJUgwAYV5LP2XMncHvNJlo61HFdRFIv0ZvnLwJ/cvergAfMrDiJMR3AzK4wsxozq2loaEjlqfu1fU87Hd09SatBAHzs5Cqa27q4V3NWi0gaJNKT+p+AO4DrwlWVwD1DcO46YErc+8nhugO4+/XuvsjdF1VUVAzBqQ/fpiQ9wRRv0bQyjppQzE1Pb8D9gPESRUSSKpEaxKeBUwjmgcDd3wDGDcG5lwKXhE8znQg09WkMz2h1jb2d5JJXgzAzPnZyFa/WN/Pc+oGac0REhl4iCaLd3Tt635hZNhHDf/dlZrcCTwNzzKzWzD5hZlea2ZVhkfuAdcAa4OfApwYdfRolqw9EXxcsqGTMqFyue2JdUs8jItJXImMxPW5mXwcKzOwsgi/yPxxsJ3e/6CDbnaB2MizV7mqhtDCHvOyspJ6nIDeLS0+u4gcPreb1LbuZMyGlzT8icgRLpAbxVaABWA78M8Ev/39NZlDDQV1jK5PLUjOY3iUnTaMwN4vrHl+bkvOJiMBBEoSZZQE3u/vP3f1D7v7BcPmIbzGt3dVKZYpGWy0tzOWixVO59+XN+8Z/EhFJtgEThLt3A9PMLHktscOQe9AHYnLZ0EwUlIhPnFqNATc8uT5l5xSRI1sibRDrCGaRWwrsG/fB3X+QtKgy3K6WTlo7u1NWgwCYVFrA+Qsque35TXzunbMYM0o5W0SSq98ahJndHC6eB/wxLFsc9zpi9d7mSVUbRK8rT59OW1c3P39STzSJSPINVIM4wcwmARuBn6QonmGh9xHXyrICtu/pOEjpoTNrfDHnzZ/EL/+6no+fUsW44vyUnVtEjjwDJYhrgYeBaqAmbr0R9IOYnsS4MlptmCAmlxby8qamlJ77qnfN5k+v1HPNI2v4zvlzueXZA+evvnhJIoPtiogMrN9bTO5+tbsfDfwynHK091Xt7kdscoDgEdfivGxKChJpwhlaVeWj+Ie3TeHW5zayaaeeaBKR5ElkNNdPpiKQ4aR2VwuVZQWYpWc60M+dOYuYGT/8y+q0nF9EjgxDOxXaEaJ2V+o6yUWZMDqfj51cxd0v1bG1uS1tcYjIyJb6eyQjwObGVhZXj0na8aPaFfoaV5RHXnaM+5bXc+nJVWmrzYjIyKUaxCDtae+iua2LiaPTV4MAKMzL5syjxvPGtj28vnV3WmMRkZFJCWKQ6sNhvieVpv8R0xOnj6G8KI8/vVJPV09PusMRkRFGCWKQNjcF9/wnpbAXdX+yYzHOPW4iO/Z28PTaHekOR0RGGCWIQeqtQUwcnf4aBMDs8cXMGV/MI69tY3dbZ7rDEZERRAlikDY3tWEG40syI0EAvHfeRLq6nQdWbk13KCIygihBDFJ9YyvjivPIycqcS1denMcpM8t5ceMuNuzYe/AdREQSkDnfcsNEfVNb2p9givKOoyoYXZDD0pc309WtBmsROXxKEIO0uak1I55g6isvO4v3zptIfVMbv3lmQ7rDEZERQAliENyd+sbMrEEAHDuphFnjivj+g6vZtls9rEXk8ChBDEJTazBRUKY8wdSXmfG+4ybR1tXNf973WrrDEZFhTgliEDY3Zk4fiP6UF+dx+dunc9dLdbywYVe6wxGRYUwJYhDqmzKrD0R/PvOOmYwvyePbS1fS0+PpDkdEhikliEHIpF7UAxmVl83X33M0y+uauL1mU7rDEZFhSgliEOobW8mOGeVFeekO5aDOmz+Jt1WV8d8PvE5Tq3pYi8jgKUEMwubGVsaX5JMVy/yhtc2Mb593LI0tHfxIEwuJyCFQghiEzU1tGdkHoj/HThrNh982lZuf3sC6hj3pDkdEhhlNGDQI9U2tHD+lLN1hDMoXz5rN0mV1fOaWl/jHE6ftt+3iJVPTFJWIDAeqQSSop8fZ0tTGxGFUgwCoKM7jU++Yyar6ZtUiRGRQVINI0Pa97XR2O5UZ/gQTHDhlaVFeNqMLcrhvRT2fOmMmMU1PKiIJUA0iQfVhJ7lMHWZjIDlZMd597Hg2N7axbGNjusMRkWFCCSJBw6WTXH+Om1zK5LICHly1hY4ujfYqIgenBJGg4TDMxkBiZpwzdyLNbV38de32dIcjIsOAEkSC6ptaycuOUVaYk+5QDll1+SiOmVjC46sbND2piByUEkSCgj4QBdgwb+A9+9gJdHX38Mhr29IdiohkOCWIBNU3tg7b9od45cV5LK4ey/Nv7mTNNj32KiL9U4JIUKZONXoozjxqHDlZMf7vfa+mOxQRyWBKEAno6Opha3MblcOsk1x/ivKyOfOocTz82jYeeW1rusMRkQylBJGAzY2t9DhMHTsq3aEMmZNmjGXmuCK+vXQVbZ3d6Q5HRDJQUhOEmZ1tZq+b2Roz+2rE9kvNrMHMloWvy5MZz6HasLMFgKljCtMcydDJjsX4znnHsnFnC9c9vi7d4YhIBkpagjCzLOB/gHOAY4CLzOyYiKK3ufuC8HVDsuI5HBtHYIIAOHlmOe89biI/fWwNm8K/UUSkVzJrEIuBNe6+zt07gN8B5yfxfEmzaWcLedkxxhVn/kRBg/Wv7z2arJjxraUrcdf0pCLylmQmiEogfr7L2nBdXx8ws1fM7A4zmxJ1IDO7wsxqzKymoaEhGbEOaMOOvUwZU0hsGEwUNFgTRxfwxbNm88hr2/jNMxvSHY6IZJB0N1L/Aahy9+OAh4BfRxVy9+vdfZG7L6qoqEhpgAAbd7aOuNtL8S47pZoz5lTw3T+9yqrNzekOR0QyRDITRB0QXyOYHK7bx913uHt7+PYG4IQkxnNI3J1NO1tGdIKIxYzvfWg+pQU5fObWF2np6Ep3SCKSAZKZIJ4HZplZtZnlAhcCS+MLmNnEuLfnARnXc2tXSyd72rtGdIIAKC/K40cfXsD67Xv517tXqD1CRJKXINy9C/gM8ADBF//t7r7SzL5jZueFxT5nZivN7GXgc8ClyYrnUG3YsRcYeU8wRTl5Zjmff+cs7nqpjm/eu5KeHiUJkSNZUmeUc/f7gPv6rPtm3PLXgK8lM4bDte8R17EjP0EAfP6ds2jt6Oa6J9bR2d3Df/z9vBHZOC8iB6cpRw+it3/AlLIjI0GYGV895yhysmJc8+gaOrp6+I/3zyM/JyvdoYlIiilBHMSGHS2MK86jIHfkfUH2nbu618VLpvKld88hLzvG9x9azbLaRr7/ofkcP7UsxRGKSDql+zHXjLdxhD/BNJDPvnMWv/nEEto6uvnAz/7Gf//5NVo7NG6TyJFCNYiD2LSzhROnj013GGlz6qxy/nzVaXz3D6v46WNrufulOr589hzOn1/J757fdED5i5dMTUOUIpIMShADaO/qpr657YhpoO4Vdevp+KlllBbmct/yeq667WW+/+Bqzl9QSeUwnaNbRA5Ot5gGULurFfcj4xHXRFSXj+KTZ8zggwsn09jSyc8eW8P9y+vp6OpJd2gikgSqQQxgpI7iejhiZiycVsbRE0u4f0U9T67ZzorNTXz4bVN1nURGGNUgBrDpCOsDMRgFuVm8f+FkLn97NQA/f2Idz67foR7YIiOIEsQANuxoIT8nRkXRyBvme6hMLy/i0++YyYxxo7h32Wa+9PtXNEOdyAihBDGA3kdczdSTeCCFudlcclIVZx41jjtfrOWSG5+jqbUz3WGJyGFSG8QARvoorkMpZsa7jh5PRXEed9TU8u4fPsHHTq5idEEOoMdfRYYj1SD64e5hDWJUukMZVuZPLuVjJ1exs6WD6x5fS8Pu9oPvJCIZSQmiH3WNrbR0dFNdoQQxWDPHFfFPb59OZ49z/RNrqW9qTXdIInIIlCD6saIumFlt7qSSNEcyPFWWFnDF26eTnRXj50+u44UNu9IdkogMkhJEP1bUNZEVM46eqARxqCqK87jitOkU5mbz0Ruf5a9rtqc7JBEZBCWIfqzY3MSscUUa5vowlRXmcsVp05lSVsjHf/k89y+vT3dIIpIgJYgI7s6KuibmVo5OdygjQkl+Drf/80nMmzyaT9/yIrc+Fz3MuIhkFiWICFua29i+p0PtD0NodGEON39iMafNruBrdy3nmkfeUK9rkQynfhARehuo501WDWIoFeZm8/NLFvHlO17hew+u5vHVDZw3v5KsuClN1V9CJHMoQURYXtdEzFADdRLkZMX4wT/MZ1JpPv/z6FqaW7u4cPEU8rLV1iOSaZQgIqysa2JGRRGFubo8Q6XvHBOVpYVcsKCSe5fVcf0T6/joidMoLcxNU3QiEkVtEBGW1zUxTw3USbe4egyXnFTFzr0d/PSxtWzcsTfdIYlIHCWIPrY1t7FtdzvHKkGkxJwJxVx5+gxys2P8/Kn1/L7mwGlMRSQ9lCD6WLG5CUA1iBQaX5LPp06fwbQxhfyvO17hi7cvY297V7rDEjni6SZ7H8trmzGDY/SIa0oV5mVz2anVNOxu5+pH3mDZpkauvvB49UURSSPVIPpYsbmJ6vJRFOUpd6ZazIyrzprNLZefyJ62Ls675im+cfdyduzRiLAi6aAE0ccKNVCn3UkzxvLgVadxyUlV/O75TZzxvcf4n0fXaFRYkRTTz+Q4W5raqG9qY+4kJYh0iX8cdvb4Yj7zjpm8XNvI/3vgdb734OucPGMsZ8+dyDETS3hlUyN5fcbKUkc7kaGjBBHnj69sBuDMo8elORLpNb4kn199fDFvbt/L3S/Vcc+yOv7tnhX7to8uyKE4P5uivGyK87N5+NWtlBTkUFqQw7iSfErys/nIidPS+BeIDF9KEHHuerGO+ZNHM6OiKN2hSB9V5aO46qzZfOFds6jd1crrW3ZzW80mtu9uZ097F02tnWza1XrA00/5OTHuXbaZhdPKWFxdxgnTxuybBlVEBqYEEXp9y25W1Tfz7fcdk+5QZABmxpQxhUwZU8i2iOlMu3p62N3Wxa6WDrY1t7O1uY2O7h5ufGod1z7umAXTop4+u4LT51Qwf3LpfmNBichblCBCd79UR1bMOHf+pHSHIochOxajrDCXssJcppe/VRM8f34lm3a1sH77Xt7YupurH36DHz/8BmNG5XLG7ArecdQ4TptVwehC1S5EeilBAD09zr3L6jh9dgXlRXnpDkeSIDc7xoyKImZUFPGuo8fT0t7FGw17eH3Lbu5fsYW7XqojZrBwahlnzKng1FkVzJ1UQnaWHvSTI5cSBPDMuh3UN7Xx9fccne5QJELfgf6GQmFeNvMnlzJ/cik97mza2cLqrbvZvqeD7z24mu89uJri/GyWVI/lxOljeFvVGI6ZVELOECWMqL9JT2BJplGCILi9VJSXzVnHjE93KJIGMTOmjR3FtLGjuHjJVLbvaefptTv429rt/G3tDv7y6lYAcrKMyWWFTC4r4KLFU5lXOZrK0gJiasOQEeqITxAtHV3cv2IL58ydoPmnZb9f9vMqS5lXWUpzaycbdrbw5va9bNrVwt/W7uDJN7YDMCo3izkTiplRUcTkskIqywoYX5K377Hb/JwszA5MIE2tneRnx8jNjkVuF8kER3SCcHe+cudy9nZ0cZGq99KPkoIc5lWO3tfDvqu7h/qwU+WW5ja2NLXxxrYt7G4b/ACDMYOC3GzKR+Xy8qZGZo4rYsHUUuZVjtYPFkm7IzpB/PSxtfzh5c185eyjWDi1LN3hyDCRnRXb96htvM7uHppaO9nd1kVHVzdtXT10dvVw4vSxBxzjb2t30NbZTVtnN3vau9i+p4OHX9vKbeFw5zlZxtzK0SyuHsOS6jHqvyFpkdQEYWZnAz8GsoAb3P0/+2zPA24CTgB2AB929zeTGVOvh1Zt5XsPvs75CyZx5enTU3FKGeFysmKUF+Ud8CRcV48fUHZx9ZgD1vW2f7y0sZGaDTt54c1d/PKpN7nu8XWYwcyKIo6bXMr8KaOZM76YGeOKGDsqV7eoJGnM/cD/eYfkwGZZwGrgLKAWeB64yN1XxZX5FHCcu19pZhcCf+/uHx7ouIsWLfKamppDjmt3Wye319TygwdfZ3pFEb+/8qTDqson4wkbkV6d3T1s2tnC+h17qd3ZSm3j/r3FS/KzmTKmkImjC5hUms+44jzGjMpjzKhcSguDYUiK83IoyM0iNztGblaMrJjRm1Pcoccdd3D2/y7Iihk5sZga4UcIM3vB3RcNZp9k1iAWA2vcfR2Amf0OOB9YFVfmfODb4fIdwDVmZp6ErLVpZwu/+Ot6fl9Ty572LhZXj+HHFy7QfV7JaDlZMaZXFDE9HP7F3Wlq7WTb7nYadrfTsKedxpYOVtQ18dSaBto6e4Y8BjPIy46Rl51FXnaMgtws8rOzyM8JGtnjEw8YMYMeh+6eHro96GfU1dNDd0+QiBr2tGMYWbHg78vJCo6xYErpvsb9kvwcSgqyKcrLoTAvi1G52RTkZO07X3aWkWVGzPZPdo7T05v0eoJ/g1dw7Tws19/faQS99WMWPN0WM8Nib62H3uW39gvO+9bxDzgucccKj5sVC86R6bW/ZCaISiB+/shaYEl/Zdy9y8yagLHA9qEOZlV9M795ZgPnHjeJy06pZt5kjdgqw4+ZUVqYS2lhLrPHFx+wvau7h70dQbtGbxtHW2cPnd3BF3RXT/CFGS9G9BdVjzvd7nT3ON3dTmeP09UdHKuz22np6Ka5rSvY3uOUFubs+yLu/RLc1dKx78sxzB9kmeEQHqOTzm6no6ub5XVNdHQNfYLLdL3JyMKEEZ+ADNsvGV1+ajVf/Ls5KYttWDRSm9kVwBXh2z1m9vqhHutH4WsIlZOEhHaYFFPiMjEuxZSYTIwJkhjXv4SvQ1AODHpY42QmiDpgStz7yeG6qDK1ZpYNjCZorN6Pu18PXJ+kOA+LmdUM9r5esimmxGViXIopMZkYE2RmXGFMVYPdL5kDzTwPzDKzajPLBS4ElvYpsxT4WLj8QeCRZLQ/iIjI4CWtBhG2KXwGeIDgMddfuPtKM/sOUOPuS4EbgZvNbA2wkyCJiIhIBkhqG4S73wfc12fdN+OW24APJTOGFMjEW1+KKXGZGJdiSkwmxgSZGdchxZS0fhAiIjK8abB7ERGJpASRADP7hZltM7MV/Ww3M7vazNaY2StmtjADYjrDzJrMbFn4+mZUuSGOaYqZPWpmq8xspZl9PqJMSq9VgjGl41rlm9lRXM3IAAAIL0lEQVRzZvZyGNf/jiiTZ2a3hdfqWTOryoCYLjWzhrhrdXkyY4o7b5aZvWRmf4zYltLrlGBM6bpOb5rZ8vCcBww5MejPn7vrdZAXcBqwEFjRz/b3APcTdJo8EXg2A2I6A/hjiq/TRGBhuFxMMNTKMem8VgnGlI5rZUBRuJwDPAuc2KfMp4Brw+ULgdsyIKZLgWtSea3C834RuCXqv1Oqr1OCMaXrOr0JlA+wfVCfP9UgEuDuTxA8ZdWf84GbPPAMUGpmE9McU8q5e727vxgu7wZeJegtHy+l1yrBmFIu/Pv3hG9zwlffBsHzgV+Hy3cA77Qkjs2QYEwpZ2aTgfcCN/RTJKXXKcGYMtWgPn9KEEMjaliRtH8JASeFtwvuN7NjU3nisJp/PMGv0Hhpu1YDxARpuFbhLYplwDbgIXfv91q5exfQOxRNOmMC+EB4e+IOM5sSsX2o/Qj4MtDfOBwpv04JxASpv04QJPQHzewFC0ag6GtQnz8liJHrRWCau88HfgLck6oTm1kRcCfwBXdvTtV5B3KQmNJyrdy9290XEIwysNjM5qbivIcZ0x+AKnc/DniIt365J4WZnQtsc/cXknmewUgwppRepzinuvtC4Bzg02Z22uEcTAliaCQyrEhKuXtz7+0CD/qj5JhZebLPa2Y5BF/Ev3X3uyKKpPxaHSymdF2ruPM3Ao8CZ/fZtO9a2QBD0aQyJnff4e7t4dsbCOZySaZTgPPM7E3gd8CZZvabPmVSfZ0OGlMarlPveevCf7cBdxOMqh1vUJ8/JYihsRS4JHxC4ESgyd3r0xmQmU3ovQ9rZosJ/lsn9cslPN+NwKvu/oN+iqX0WiUSU5quVYWZlYbLBQTzprzWp1hKh6JJJKY+96vPI2jTSRp3/5q7T/ZgHKELCa7BP/YpltLrlEhMqb5O4TlHmVlx7zLwd0DfpxwH9fkbFqO5ppuZ3UrwpEu5mdUC3yJowMPdryXoLf4eYA3QAnw8A2L6IPBJM+sCWoELk/mhCZ0CfBRYHt7HBvg6MDUurlRfq0RiSse1mgj82oKJtWLA7e7+R0vvUDSJxPQ5MzsP6ApjujTJMUVK83VKJKZ0XKfxwN3hb51s4BZ3/7OZXQmH9vlTT2oREYmkW0wiIhJJCUJERCIpQYiISCQlCBERiaQEISIikZQgREQkkhKEiIhEUoKQjGJmew5eqt99C8zs8bCjV9KY2Q3heDyY2ffDQf5+ksxzJpOZ5ZrZE+EwFSL7KEHISHIZcJe7dw/VAftJNscDy8xsBnCKu893988msF9GcvcO4GHgw+mORTKLEoRkJDP7opmtCF9fiFv/b2b2upk9ZWa3mtmX4nb7CHBvWK7KzJ4IlxeamZtZeTic9XIzKzSzo8zsEQtm3/pL7wB9ZvZ7M7vOzJ4BvmZms8PzLTezbwATgFHAY8A0C2YVGxWxX7WZ3WtmNRbM1DYnPP4sM3ss/Nu+b2Zr4/6+p82sOlyuNLMXwuX+jnWXmf17WAPYaGbvCtdPMrM7w9heM7PFZjbXzP4Wd66FZvZw+Pae8PqJvCWRWYr00itVL2APwciXywm+hIuAlQS/2t8GLAPyCWaHewP4UrhfLrAl7jilwIvh8i+Bp4GZBAOn/RDIC4+7ICzzFeD/hMuvAd8Jl3vLLQ7f/xR4OFz+d+DyuHPG75dD8Kt8Rvj+PWEcWWEsvbPc/QRYGi7HgM28NQTOOeE+kccKl+Ovwd+H5bOBl4Fzw/WF4fWKAVuArHD9Y3FxZAEN6f7vr1dmvXTPUTLRqcDd7r4Xgl/JwNsJvuDudfc2oM3M/hC3TznQGPe+GSgMawUTgb8CZcAVBFNFXgA85e69A/itIhjCOR8YA3wnXH8BwQBsz4XvVwJt4fI83qqxRO13LHBn3OBpT4brV3k4yx3BKJ+9cc8A1rt77wBpxxEkyshjmVkhwdDWPwzL54THuoBg9No/Arh7S+9FMbOVwLFmNgvY4G/NttdtZh1mVuzBzHsiShAyYrQS1CwAcPceM3PgcoLRPo8B5hP8el5tZh8h+PLtNY8gSRxLME9vV9z6+IlhTiD45U1YdkXccvx+84FvuPuN8UGa2b8T1IKIK/eXuHPFx7QIuB44vZ9jLQJe8LfaXI4L41kAPEO0ZwhGuP0UB84/kcdbyU9EbRCSkZ4ELgjbCUYR3Dp5kqAW8D4zy7dghrhze3dw911AVvhLvlcPwS2luwlqFP8CXBtuqyNIGpjZdIIhwW8i+JJ+Je4YO4C5YbkTgIuAly0Yd7/T3VvDcn33qwfebWaxcN95Fvz83wEcFa5bAlxCcDsIghpIY7jtaII5j18Z4Fjz2D/ZHBeW30KQsAjLV8SVeYbg1tjdHk4uE5YZC2x3905EQkoQknHC2x6/Ap4jmD/6Bnd/yd2fJ5jw5BXgfoJf201xuz5IcHuqVydwf/irvpngXvwfw203A5PMbDnBrGCXufsODvyivxlYYMFcEl8m+AJfRZA04idj6bvfLwg+X6+G+34lvHV0M7AoPO/7CRLGmnCfB4Czzey3wIeAHe6+dYBj9U0QvTH9ChhvZivD8ifFlXkNaAf+i/29A/gTInE0H4QMK2ZW5O57wvvvTwBX9N5HN7OFwFXu/tG0BpkgCyayv8Pdl6TwnNcAz7v7r/usvwv4qruvTlUskvlUg5Dh5vrwV/GLwJ1xjb29NY9Hh1EfhPnsX+tIGjObYWavAQURySEXuEfJQfpSDUJERCKpBiEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJQgREYn0/wEMGxbYk6/33AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28859f4f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(np.log10(filtered_unigrams_dict.values()))\n",
    "ax.set_xlabel(r'$\\log(word frequency)$')\n",
    "ax.set_ylabel(r'frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(cut_sentences)\n",
    "n_valid = int(n_samples * 0.2)\n",
    "n_test = int(n_samples * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_sentences = np.array(cut_sentences)[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = shuffled_sentences[:n_samples-n_test-n_valid]\n",
    "valid = shuffled_sentences[n_samples-n_test-n_valid:n_samples-n_test]\n",
    "test = shuffled_sentences[n_samples-n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Language Model on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_dict, n_unigrams = ngrams_parameter_estimate(train, 1)\n",
    "bigrams_dict, n_bigrams = ngrams_parameter_estimate(train, 2)\n",
    "trigrams_dict, n_trigrams = ngrams_parameter_estimate(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Our Uni-, Bi-, Tri-gram Model on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sentence_log_probability(sentence, n, num_grams, ngrams_dict, n_1grams_dict=None):\n",
    "    assert len(ngrams_dict.keys()[0]) == n, n\n",
    "    if n_1grams_dict is None:\n",
    "        assert n == 1\n",
    "    ngrams = generate_ngrams(sentence, n)\n",
    "    log_prob, has_unknown_ngram = 0.0, False\n",
    "    for ngram in ngrams:\n",
    "        if ngram in ngrams_dict:\n",
    "            if n == 1:\n",
    "                log_prob += np.log2(ngrams_dict[ngram]/num_grams)\n",
    "            else:\n",
    "                log_prob += np.log2(ngrams_dict[ngram]/n_1grams_dict[ngram[:n-1]])\n",
    "        else:\n",
    "            has_unknown_ngram = True\n",
    "    return 0.0 if has_unknown_ngram else log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_total_words(sentences):\n",
    "    \n",
    "    return np.sum([len(s) for s in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words_in_test = compute_total_words(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134962"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_in_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in test: 134962\n",
      "Perplexity for uni gram language model: 15.523578348\n",
      "Perplexity for bi gram language model: 1.08625145142\n",
      "Perplexity for tri gram language model: 1.0075007939\n"
     ]
    }
   ],
   "source": [
    "ngrams_list = [unigram_dict, bigrams_dict, trigrams_dict]\n",
    "ngrams_names = ['uni', 'bi', 'tri']\n",
    "print \"Number of words in test: {}\".format(n_words_in_test)\n",
    "for n in range(1, 4):\n",
    "    sum_log_prob = 0.0\n",
    "    for s in test:\n",
    "        if n == 1:\n",
    "            sum_log_prob += calculate_sentence_log_probability(s, n, n_unigrams, ngrams_list[n-1])\n",
    "        else:\n",
    "            sum_log_prob += calculate_sentence_log_probability(s, n, n_unigrams, ngrams_list[n-1], ngrams_list[n-2])\n",
    "    perplexity = 2**(-sum_log_prob/n_words_in_test)\n",
    "    \n",
    "    print \"Perplexity for {} gram language model: {}\".format(ngrams_names[n-1], perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in valid: 90010\n",
      "Perplexity for uni gram language model: 13.5866633607\n",
      "Perplexity for bi gram language model: 1.09317499808\n"
     ]
    }
   ],
   "source": [
    "n_words_in_valid = compute_total_words(valid)\n",
    "print \"Number of words in valid: {}\".format(n_words_in_valid)\n",
    "for n in range(1, 4):\n",
    "    sum_log_prob = 0.0\n",
    "    for s in valid:\n",
    "        if n == 1:\n",
    "            sum_log_prob += calculate_sentence_log_probability(s, n, n_unigrams, ngrams_list[n-1])\n",
    "        else:\n",
    "            sum_log_prob += calculate_sentence_log_probability(s, n, n_unigrams, ngrams_list[n-1], ngrams_list[n-2])\n",
    "    perplexity = 2**(-sum_log_prob/n_words_in_valid)\n",
    "    \n",
    "    print \"Perplexity for {} gram language model: {}\".format(ngrams_names[n-1], perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_1 = 0.2#lambda for unigram\n",
    "lambda_2 = 0.3#lambda for bigram\n",
    "lambda_3 = 0.5#lambda for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_log_probability_with_linear_interpolation(sentence, num_grams, ngrams_list, lambdas):\n",
    "    ngrams = generate_ngrams(sentence, 3)\n",
    "    log_prob, has_unknown_ngram = 0.0, False\n",
    "    for ngram in ngrams:\n",
    "        if ngram in ngrams_list[2]:\n",
    "            prob = 0.0\n",
    "            for i in range(3):\n",
    "                if i == 0:\n",
    "                    prob += ngrams_list[i][ngram[:i+1]]*lambdas[i]/num_grams\n",
    "                else:\n",
    "                    prob += ngrams_list[i][ngram[:i+1]]*lambdas[i]/ngrams_list[i-1][ngram[:i]]\n",
    "            log_prob += np.log2(prob) if prob > 0.0 else 0.0\n",
    "        else:\n",
    "            has_unknown_ngram = True\n",
    "    return 0.0 if has_unknown_ngram else log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words_in_valid = compute_total_words(valid)\n",
    "lambdas = [lambda_1, lambda_2, lambda_3]\n",
    "print \"Number of words in valid: {}\".format(n_words_in_valid)\n",
    "sum_log_prob = 0.0\n",
    "for s in valid:\n",
    "    sum_log_prob += sentence_log_probability_with_linear_interpolation(s, n_unigrams, ngrams_list, lambdas)\n",
    "perplexity = 2**(-sum_log_prob/n_words_in_valid)\n",
    "    \n",
    "print \"Perplexity for smoothed trigram language model: {}\".format(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_search_lambdas(sentences, n_iter, n_unigrams, ngrams_list, verbose=True):\n",
    "    best_lambda_1, best_lambda_2, best_lambda_3 = None, None, None\n",
    "    best_log_prob = -np.inf\n",
    "    for i in range(n_iter):\n",
    "        lambda_1 = np.random.uniform(0, 1)\n",
    "        lambda_2 = np.random.uniform(0, 1)\n",
    "        lambda_3 = 1.0 - lambda_1 - lambda_2\n",
    "        lambdas = [lambda_1, lambda_2, lambda_3]\n",
    "        sum_log_prob = 0.0\n",
    "        for s in valid:\n",
    "            sum_log_prob += sentence_log_probability_with_linear_interpolation(s, n_unigrams, ngrams_list, lambdas)\n",
    "        if sum_log_prob > best_log_prob:\n",
    "            best_log_prob = sum_log_prob\n",
    "            best_lambda_1, best_lambda_2, best_lambda_3 = tuple(lambdas)\n",
    "        if verbose:\n",
    "            print \"current best log_prob: {}\".format(best_log_prob)\n",
    "            \n",
    "    return [best_lambda_1, best_lambda_2, best_lambda_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambdas = random_search_lambdas(valid, 10, n_unigrams, ngrams_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words_in_test = compute_total_words(test)\n",
    "print \"Number of words in test: {}\".format(n_words_in_test)\n",
    "sum_log_prob = 0.0\n",
    "for s in test:\n",
    "    sum_log_prob += sentence_log_probability_with_linear_interpolation(s, n_unigrams, ngrams_list, best_lambdas)\n",
    "perplexity = 2**(-sum_log_prob/n_words_in_test)\n",
    "    \n",
    "print \"Perplexity for smoothed trigram language model: {}\".format(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "1. Use Laplace smoothing to redo the above test.\n",
    "\n",
    "\n",
    "2. (Optional) Learnin discount smoothing method and redo the above test.\n",
    "\n",
    "\n",
    "3. (Optional) You can learn nltk package and do the above analysis. The results may be different since nltk handle unknown words automatically. Also, you have to clean data by yourself since nltk do not support Chinese very well. Install nlkt: pip install nltk. Be carefore about the NgramModel in nltk, they are working on fixing bugs and you cannot currently import nltk.model.ngram.NgramModel :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔可夫过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = ['我', '是', '中国人']\n",
    "emission_prob = {\n",
    "    ('N', '我'): 0.01,\n",
    "    ('N', '中国人'): 0.002,\n",
    "    ('V', '是'): 0.05\n",
    "}\n",
    "transition_prob = {\n",
    "    ('*', 'N'): 0.02,\n",
    "    ('*', 'V'): 0.0009,\n",
    "    ('N', 'V'): 0.05,\n",
    "    ('V', 'N'): 0.04\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_taggers = 2\n",
    "tagger_encoder = LabelEncoder()\n",
    "encoded_taggers = tagger_encoder.fit_transform(['N', 'V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dynamic_table = np.ones([n_taggers, len(sentence)], dtype=np.float32)*(-1)\n",
    "for j in range(n_taggers):\n",
    "    tagger_to_tagger = ('*', tagger_encoder.inverse_transform(j))\n",
    "    word_on_tagger = (tagger_encoder.inverse_transform(j), sentence[0])\n",
    "    dynamic_table[j, 0] = transition_prob.get(tagger_to_tagger,0.0)*emission_prob.get(word_on_tagger,0.0)\n",
    "for i in range(1, len(sentence)):\n",
    "    for j in range(n_taggers):\n",
    "        word_on_tagger = (tagger_encoder.inverse_transform(j),sentence[i])\n",
    "        max_at_i = 0.0\n",
    "        # loop all states in previous step\n",
    "        for k in range(n_taggers):\n",
    "            tagger_to_tagger = (tagger_encoder.inverse_transform(k),tagger_encoder.inverse_transform(j))\n",
    "            prob_k_j = dynamic_table[k, i-1]*transition_prob.get(tagger_to_tagger,0.0)\n",
    "            if max_at_i < prob_k_j:\n",
    "                max_at_i = prob_k_j\n",
    "        dynamic_table[j, i] = max_at_i\n",
    "        tmp = dynamic_table[j, i]\n",
    "        dynamic_table[j, i] = dynamic_table[j, i]*emission_prob.get(word_on_tagger, 0.0)\n",
    "\n",
    "back_pointer = np.ones((len(sentence, )), dtype=np.int32)*(-1)\n",
    "for i in range(len(sentence) - 1, -1, -1):\n",
    "    max_at_i = 0.0\n",
    "    max_j = 0.0\n",
    "    for j in range(n_taggers):\n",
    "        if dynamic_table[j, i] > max_at_i:\n",
    "            max_at_i = dynamic_table[j, i]\n",
    "            max_j = j\n",
    "            back_pointer[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Decoding result: ', tagger_encoder.inverse_transform(back_pointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use nltk to build Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = treebank.tagged_sents()[:3000]\n",
    "\n",
    "print train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tagger\n",
    "\n",
    "print tagger.tag(\"Today is a good day .\".split())\n",
    "\n",
    "print tagger.tag(\"Joe met Joanne in Delhi .\".split())\n",
    "\n",
    "print tagger.tag(\"Chicago is the birthplace of Ginny\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow35",
   "language": "python",
   "name": "tensorflow35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
